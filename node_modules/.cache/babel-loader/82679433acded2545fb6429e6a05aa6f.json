{"ast":null,"code":"import _classCallCheck from \"/Users/jenniferhe/Documents/GitHub/oval/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _createClass from \"/Users/jenniferhe/Documents/GitHub/oval/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport { decodeErrPrefix } from './common.js';\nimport { Type } from './token.js';\nimport { jump, quick } from './jump.js';\nvar defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n};\n\nvar Tokeniser = /*#__PURE__*/function () {\n  function Tokeniser(data) {\n    var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n    _classCallCheck(this, Tokeniser);\n\n    this.pos = 0;\n    this.data = data;\n    this.options = options;\n  }\n\n  _createClass(Tokeniser, [{\n    key: \"done\",\n    value: function done() {\n      return this.pos >= this.data.length;\n    }\n  }, {\n    key: \"next\",\n    value: function next() {\n      var byt = this.data[this.pos];\n      var token = quick[byt];\n\n      if (token === undefined) {\n        var decoder = jump[byt];\n\n        if (!decoder) {\n          throw new Error(\"\".concat(decodeErrPrefix, \" no decoder for major type \").concat(byt >>> 5, \" (byte 0x\").concat(byt.toString(16).padStart(2, '0'), \")\"));\n        }\n\n        var minor = byt & 31;\n        token = decoder(this.data, this.pos, minor, this.options);\n      }\n\n      this.pos += token.encodedLength;\n      return token;\n    }\n  }]);\n\n  return Tokeniser;\n}();\n\nvar DONE = Symbol.for('DONE');\nvar BREAK = Symbol.for('BREAK');\n\nfunction tokenToArray(token, tokeniser, options) {\n  var arr = [];\n\n  for (var i = 0; i < token.value; i++) {\n    var value = tokensToObject(tokeniser, options);\n\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n\n      throw new Error(\"\".concat(decodeErrPrefix, \" got unexpected break to lengthed array\"));\n    }\n\n    if (value === DONE) {\n      throw new Error(\"\".concat(decodeErrPrefix, \" found array but not enough entries (got \").concat(i, \", expected \").concat(token.value, \")\"));\n    }\n\n    arr[i] = value;\n  }\n\n  return arr;\n}\n\nfunction tokenToMap(token, tokeniser, options) {\n  var useMaps = options.useMaps === true;\n  var obj = useMaps ? undefined : {};\n  var m = useMaps ? new Map() : undefined;\n\n  for (var i = 0; i < token.value; i++) {\n    var key = tokensToObject(tokeniser, options);\n\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n\n      throw new Error(\"\".concat(decodeErrPrefix, \" got unexpected break to lengthed map\"));\n    }\n\n    if (key === DONE) {\n      throw new Error(\"\".concat(decodeErrPrefix, \" found map but not enough entries (got \").concat(i, \" [no key], expected \").concat(token.value, \")\"));\n    }\n\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(\"\".concat(decodeErrPrefix, \" non-string keys not supported (got \").concat(typeof key, \")\"));\n    }\n\n    var value = tokensToObject(tokeniser, options);\n\n    if (value === DONE) {\n      throw new Error(\"\".concat(decodeErrPrefix, \" found map but not enough entries (got \").concat(i, \" [no value], expected \").concat(token.value, \")\"));\n    }\n\n    if (useMaps) {\n      m.set(key, value);\n    } else {\n      obj[key] = value;\n    }\n  }\n\n  return useMaps ? m : obj;\n}\n\nfunction tokensToObject(tokeniser, options) {\n  if (tokeniser.done()) {\n    return DONE;\n  }\n\n  var token = tokeniser.next();\n\n  if (token.type === Type.break) {\n    return BREAK;\n  }\n\n  if (token.type.terminal) {\n    return token.value;\n  }\n\n  if (token.type === Type.array) {\n    return tokenToArray(token, tokeniser, options);\n  }\n\n  if (token.type === Type.map) {\n    return tokenToMap(token, tokeniser, options);\n  }\n\n  if (token.type === Type.tag) {\n    if (options.tags && typeof options.tags[token.value] === 'function') {\n      var tagged = tokensToObject(tokeniser, options);\n      return options.tags[token.value](tagged);\n    }\n\n    throw new Error(\"\".concat(decodeErrPrefix, \" tag not supported (\").concat(token.value, \")\"));\n  }\n\n  throw new Error('unsupported');\n}\n\nfunction decode(data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(\"\".concat(decodeErrPrefix, \" data to decode must be a Uint8Array\"));\n  }\n\n  options = Object.assign({}, defaultDecodeOptions, options);\n  var tokeniser = options.tokenizer || new Tokeniser(data, options);\n  var decoded = tokensToObject(tokeniser, options);\n\n  if (decoded === DONE) {\n    throw new Error(\"\".concat(decodeErrPrefix, \" did not find any content to decode\"));\n  }\n\n  if (decoded === BREAK) {\n    throw new Error(\"\".concat(decodeErrPrefix, \" got unexpected break\"));\n  }\n\n  if (!tokeniser.done()) {\n    throw new Error(\"\".concat(decodeErrPrefix, \" too many terminals, data makes no sense\"));\n  }\n\n  return decoded;\n}\n\nexport { Tokeniser, tokensToObject, decode };","map":{"version":3,"sources":["/Users/jenniferhe/Documents/GitHub/oval/node_modules/cborg/esm/lib/decode.js"],"names":["decodeErrPrefix","Type","jump","quick","defaultDecodeOptions","strict","allowIndefinite","allowUndefined","allowBigInt","Tokeniser","data","options","pos","length","byt","token","undefined","decoder","Error","toString","padStart","minor","encodedLength","DONE","Symbol","for","BREAK","tokenToArray","tokeniser","arr","i","value","tokensToObject","Infinity","tokenToMap","useMaps","obj","m","Map","key","set","done","next","type","break","terminal","array","map","tag","tags","tagged","decode","Uint8Array","Object","assign","tokenizer","decoded"],"mappings":";;AAAA,SAASA,eAAT,QAAgC,aAAhC;AACA,SAASC,IAAT,QAAqB,YAArB;AACA,SACEC,IADF,EAEEC,KAFF,QAGO,WAHP;AAIA,IAAMC,oBAAoB,GAAG;AAC3BC,EAAAA,MAAM,EAAE,KADmB;AAE3BC,EAAAA,eAAe,EAAE,IAFU;AAG3BC,EAAAA,cAAc,EAAE,IAHW;AAI3BC,EAAAA,WAAW,EAAE;AAJc,CAA7B;;IAMMC,S;AACJ,qBAAYC,IAAZ,EAAgC;AAAA,QAAdC,OAAc,uEAAJ,EAAI;;AAAA;;AAC9B,SAAKC,GAAL,GAAW,CAAX;AACA,SAAKF,IAAL,GAAYA,IAAZ;AACA,SAAKC,OAAL,GAAeA,OAAf;AACD;;;;WACD,gBAAO;AACL,aAAO,KAAKC,GAAL,IAAY,KAAKF,IAAL,CAAUG,MAA7B;AACD;;;WACD,gBAAO;AACL,UAAMC,GAAG,GAAG,KAAKJ,IAAL,CAAU,KAAKE,GAAf,CAAZ;AACA,UAAIG,KAAK,GAAGZ,KAAK,CAACW,GAAD,CAAjB;;AACA,UAAIC,KAAK,KAAKC,SAAd,EAAyB;AACvB,YAAMC,OAAO,GAAGf,IAAI,CAACY,GAAD,CAApB;;AACA,YAAI,CAACG,OAAL,EAAc;AACZ,gBAAM,IAAIC,KAAJ,WAAclB,eAAd,wCAA6Dc,GAAG,KAAK,CAArE,sBAAoFA,GAAG,CAACK,QAAJ,CAAa,EAAb,EAAiBC,QAAjB,CAA0B,CAA1B,EAA6B,GAA7B,CAApF,OAAN;AACD;;AACD,YAAMC,KAAK,GAAGP,GAAG,GAAG,EAApB;AACAC,QAAAA,KAAK,GAAGE,OAAO,CAAC,KAAKP,IAAN,EAAY,KAAKE,GAAjB,EAAsBS,KAAtB,EAA6B,KAAKV,OAAlC,CAAf;AACD;;AACD,WAAKC,GAAL,IAAYG,KAAK,CAACO,aAAlB;AACA,aAAOP,KAAP;AACD;;;;;;AAEH,IAAMQ,IAAI,GAAGC,MAAM,CAACC,GAAP,CAAW,MAAX,CAAb;AACA,IAAMC,KAAK,GAAGF,MAAM,CAACC,GAAP,CAAW,OAAX,CAAd;;AACA,SAASE,YAAT,CAAsBZ,KAAtB,EAA6Ba,SAA7B,EAAwCjB,OAAxC,EAAiD;AAC/C,MAAMkB,GAAG,GAAG,EAAZ;;AACA,OAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGf,KAAK,CAACgB,KAA1B,EAAiCD,CAAC,EAAlC,EAAsC;AACpC,QAAMC,KAAK,GAAGC,cAAc,CAACJ,SAAD,EAAYjB,OAAZ,CAA5B;;AACA,QAAIoB,KAAK,KAAKL,KAAd,EAAqB;AACnB,UAAIX,KAAK,CAACgB,KAAN,KAAgBE,QAApB,EAA8B;AAC5B;AACD;;AACD,YAAM,IAAIf,KAAJ,WAAclB,eAAd,6CAAN;AACD;;AACD,QAAI+B,KAAK,KAAKR,IAAd,EAAoB;AAClB,YAAM,IAAIL,KAAJ,WAAclB,eAAd,sDAA2E8B,CAA3E,wBAA4Ff,KAAK,CAACgB,KAAlG,OAAN;AACD;;AACDF,IAAAA,GAAG,CAACC,CAAD,CAAH,GAASC,KAAT;AACD;;AACD,SAAOF,GAAP;AACD;;AACD,SAASK,UAAT,CAAoBnB,KAApB,EAA2Ba,SAA3B,EAAsCjB,OAAtC,EAA+C;AAC7C,MAAMwB,OAAO,GAAGxB,OAAO,CAACwB,OAAR,KAAoB,IAApC;AACA,MAAMC,GAAG,GAAGD,OAAO,GAAGnB,SAAH,GAAe,EAAlC;AACA,MAAMqB,CAAC,GAAGF,OAAO,GAAG,IAAIG,GAAJ,EAAH,GAAetB,SAAhC;;AACA,OAAK,IAAIc,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGf,KAAK,CAACgB,KAA1B,EAAiCD,CAAC,EAAlC,EAAsC;AACpC,QAAMS,GAAG,GAAGP,cAAc,CAACJ,SAAD,EAAYjB,OAAZ,CAA1B;;AACA,QAAI4B,GAAG,KAAKb,KAAZ,EAAmB;AACjB,UAAIX,KAAK,CAACgB,KAAN,KAAgBE,QAApB,EAA8B;AAC5B;AACD;;AACD,YAAM,IAAIf,KAAJ,WAAclB,eAAd,2CAAN;AACD;;AACD,QAAIuC,GAAG,KAAKhB,IAAZ,EAAkB;AAChB,YAAM,IAAIL,KAAJ,WAAclB,eAAd,oDAAyE8B,CAAzE,iCAAmGf,KAAK,CAACgB,KAAzG,OAAN;AACD;;AACD,QAAII,OAAO,KAAK,IAAZ,IAAoB,OAAOI,GAAP,KAAe,QAAvC,EAAiD;AAC/C,YAAM,IAAIrB,KAAJ,WAAclB,eAAd,iDAAsE,OAAOuC,GAA7E,OAAN;AACD;;AACD,QAAMR,KAAK,GAAGC,cAAc,CAACJ,SAAD,EAAYjB,OAAZ,CAA5B;;AACA,QAAIoB,KAAK,KAAKR,IAAd,EAAoB;AAClB,YAAM,IAAIL,KAAJ,WAAclB,eAAd,oDAAyE8B,CAAzE,mCAAqGf,KAAK,CAACgB,KAA3G,OAAN;AACD;;AACD,QAAII,OAAJ,EAAa;AACXE,MAAAA,CAAC,CAACG,GAAF,CAAMD,GAAN,EAAWR,KAAX;AACD,KAFD,MAEO;AACLK,MAAAA,GAAG,CAACG,GAAD,CAAH,GAAWR,KAAX;AACD;AACF;;AACD,SAAOI,OAAO,GAAGE,CAAH,GAAOD,GAArB;AACD;;AACD,SAASJ,cAAT,CAAwBJ,SAAxB,EAAmCjB,OAAnC,EAA4C;AAC1C,MAAIiB,SAAS,CAACa,IAAV,EAAJ,EAAsB;AACpB,WAAOlB,IAAP;AACD;;AACD,MAAMR,KAAK,GAAGa,SAAS,CAACc,IAAV,EAAd;;AACA,MAAI3B,KAAK,CAAC4B,IAAN,KAAe1C,IAAI,CAAC2C,KAAxB,EAA+B;AAC7B,WAAOlB,KAAP;AACD;;AACD,MAAIX,KAAK,CAAC4B,IAAN,CAAWE,QAAf,EAAyB;AACvB,WAAO9B,KAAK,CAACgB,KAAb;AACD;;AACD,MAAIhB,KAAK,CAAC4B,IAAN,KAAe1C,IAAI,CAAC6C,KAAxB,EAA+B;AAC7B,WAAOnB,YAAY,CAACZ,KAAD,EAAQa,SAAR,EAAmBjB,OAAnB,CAAnB;AACD;;AACD,MAAII,KAAK,CAAC4B,IAAN,KAAe1C,IAAI,CAAC8C,GAAxB,EAA6B;AAC3B,WAAOb,UAAU,CAACnB,KAAD,EAAQa,SAAR,EAAmBjB,OAAnB,CAAjB;AACD;;AACD,MAAII,KAAK,CAAC4B,IAAN,KAAe1C,IAAI,CAAC+C,GAAxB,EAA6B;AAC3B,QAAIrC,OAAO,CAACsC,IAAR,IAAgB,OAAOtC,OAAO,CAACsC,IAAR,CAAalC,KAAK,CAACgB,KAAnB,CAAP,KAAqC,UAAzD,EAAqE;AACnE,UAAMmB,MAAM,GAAGlB,cAAc,CAACJ,SAAD,EAAYjB,OAAZ,CAA7B;AACA,aAAOA,OAAO,CAACsC,IAAR,CAAalC,KAAK,CAACgB,KAAnB,EAA0BmB,MAA1B,CAAP;AACD;;AACD,UAAM,IAAIhC,KAAJ,WAAclB,eAAd,iCAAsDe,KAAK,CAACgB,KAA5D,OAAN;AACD;;AACD,QAAM,IAAIb,KAAJ,CAAU,aAAV,CAAN;AACD;;AACD,SAASiC,MAAT,CAAgBzC,IAAhB,EAAsBC,OAAtB,EAA+B;AAC7B,MAAI,EAAED,IAAI,YAAY0C,UAAlB,CAAJ,EAAmC;AACjC,UAAM,IAAIlC,KAAJ,WAAclB,eAAd,0CAAN;AACD;;AACDW,EAAAA,OAAO,GAAG0C,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkBlD,oBAAlB,EAAwCO,OAAxC,CAAV;AACA,MAAMiB,SAAS,GAAGjB,OAAO,CAAC4C,SAAR,IAAqB,IAAI9C,SAAJ,CAAcC,IAAd,EAAoBC,OAApB,CAAvC;AACA,MAAM6C,OAAO,GAAGxB,cAAc,CAACJ,SAAD,EAAYjB,OAAZ,CAA9B;;AACA,MAAI6C,OAAO,KAAKjC,IAAhB,EAAsB;AACpB,UAAM,IAAIL,KAAJ,WAAclB,eAAd,yCAAN;AACD;;AACD,MAAIwD,OAAO,KAAK9B,KAAhB,EAAuB;AACrB,UAAM,IAAIR,KAAJ,WAAclB,eAAd,2BAAN;AACD;;AACD,MAAI,CAAC4B,SAAS,CAACa,IAAV,EAAL,EAAuB;AACrB,UAAM,IAAIvB,KAAJ,WAAclB,eAAd,8CAAN;AACD;;AACD,SAAOwD,OAAP;AACD;;AACD,SACE/C,SADF,EAEEuB,cAFF,EAGEmB,MAHF","sourcesContent":["import { decodeErrPrefix } from './common.js';\nimport { Type } from './token.js';\nimport {\n  jump,\n  quick\n} from './jump.js';\nconst defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n};\nclass Tokeniser {\n  constructor(data, options = {}) {\n    this.pos = 0;\n    this.data = data;\n    this.options = options;\n  }\n  done() {\n    return this.pos >= this.data.length;\n  }\n  next() {\n    const byt = this.data[this.pos];\n    let token = quick[byt];\n    if (token === undefined) {\n      const decoder = jump[byt];\n      if (!decoder) {\n        throw new Error(`${ decodeErrPrefix } no decoder for major type ${ byt >>> 5 } (byte 0x${ byt.toString(16).padStart(2, '0') })`);\n      }\n      const minor = byt & 31;\n      token = decoder(this.data, this.pos, minor, this.options);\n    }\n    this.pos += token.encodedLength;\n    return token;\n  }\n}\nconst DONE = Symbol.for('DONE');\nconst BREAK = Symbol.for('BREAK');\nfunction tokenToArray(token, tokeniser, options) {\n  const arr = [];\n  for (let i = 0; i < token.value; i++) {\n    const value = tokensToObject(tokeniser, options);\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(`${ decodeErrPrefix } got unexpected break to lengthed array`);\n    }\n    if (value === DONE) {\n      throw new Error(`${ decodeErrPrefix } found array but not enough entries (got ${ i }, expected ${ token.value })`);\n    }\n    arr[i] = value;\n  }\n  return arr;\n}\nfunction tokenToMap(token, tokeniser, options) {\n  const useMaps = options.useMaps === true;\n  const obj = useMaps ? undefined : {};\n  const m = useMaps ? new Map() : undefined;\n  for (let i = 0; i < token.value; i++) {\n    const key = tokensToObject(tokeniser, options);\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(`${ decodeErrPrefix } got unexpected break to lengthed map`);\n    }\n    if (key === DONE) {\n      throw new Error(`${ decodeErrPrefix } found map but not enough entries (got ${ i } [no key], expected ${ token.value })`);\n    }\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(`${ decodeErrPrefix } non-string keys not supported (got ${ typeof key })`);\n    }\n    const value = tokensToObject(tokeniser, options);\n    if (value === DONE) {\n      throw new Error(`${ decodeErrPrefix } found map but not enough entries (got ${ i } [no value], expected ${ token.value })`);\n    }\n    if (useMaps) {\n      m.set(key, value);\n    } else {\n      obj[key] = value;\n    }\n  }\n  return useMaps ? m : obj;\n}\nfunction tokensToObject(tokeniser, options) {\n  if (tokeniser.done()) {\n    return DONE;\n  }\n  const token = tokeniser.next();\n  if (token.type === Type.break) {\n    return BREAK;\n  }\n  if (token.type.terminal) {\n    return token.value;\n  }\n  if (token.type === Type.array) {\n    return tokenToArray(token, tokeniser, options);\n  }\n  if (token.type === Type.map) {\n    return tokenToMap(token, tokeniser, options);\n  }\n  if (token.type === Type.tag) {\n    if (options.tags && typeof options.tags[token.value] === 'function') {\n      const tagged = tokensToObject(tokeniser, options);\n      return options.tags[token.value](tagged);\n    }\n    throw new Error(`${ decodeErrPrefix } tag not supported (${ token.value })`);\n  }\n  throw new Error('unsupported');\n}\nfunction decode(data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(`${ decodeErrPrefix } data to decode must be a Uint8Array`);\n  }\n  options = Object.assign({}, defaultDecodeOptions, options);\n  const tokeniser = options.tokenizer || new Tokeniser(data, options);\n  const decoded = tokensToObject(tokeniser, options);\n  if (decoded === DONE) {\n    throw new Error(`${ decodeErrPrefix } did not find any content to decode`);\n  }\n  if (decoded === BREAK) {\n    throw new Error(`${ decodeErrPrefix } got unexpected break`);\n  }\n  if (!tokeniser.done()) {\n    throw new Error(`${ decodeErrPrefix } too many terminals, data makes no sense`);\n  }\n  return decoded;\n}\nexport {\n  Tokeniser,\n  tokensToObject,\n  decode\n};"]},"metadata":{},"sourceType":"module"}